{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather and preprocess text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/nakraft/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg as gut\n",
    "\n",
    "print(gut.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lightning. Enter three Witches.\n",
      "\n",
      "  1. When shall we three meet againe?\n",
      "In Thunder, Lightning, or in Raine?\n",
      "  2. When the Hurley-burley's done,\n",
      "When the Battaile's lost, and wonne\n",
      "\n",
      "   3. That will be ere the set of Sunne\n",
      "\n",
      "   1. Where the place?\n",
      "  2. Vpon the Heath\n",
      "\n",
      "   3. There to meet with Macbeth\n",
      "\n",
      "   1. I come, Gray-Malkin\n",
      "\n",
      "   All. Padock calls anon: faire is foule, and foule is faire,\n",
      "Houer through \n"
     ]
    }
   ],
   "source": [
    "macbeth_text = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
    "print(macbeth_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the tragedie of macbeth by william shakespeare actus primus scoena prima thunder and lightning enter three witches when shall we three meet againe in thunder lightning or in raine when the hurley burley done when the battaile lost and wonne that will be ere the set of sunne where the place vpon the heath there to meet with macbeth come gray malkin all padock calls anon faire is foule and foule is faire houer through the fogge and filthie ayre exeunt scena secunda alarum within enter king malcom'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_text = preprocess_text(macbeth_text)\n",
    "macbeth_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 17250\n",
      "Unique Words: 3436\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "macbeth_text_words = (word_tokenize(macbeth_text))\n",
    "n_words = len(macbeth_text_words)\n",
    "unique_words = len(set(macbeth_text_words))\n",
    "\n",
    "print('Total Words: %d' % n_words)\n",
    "print('Unique Words: %d' % unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=3437)\n",
    "tokenizer.fit_on_texts(macbeth_text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_2_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the shape of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 869, 4, 40, 60, 1358, 1359, 408, 1360, 1361, 409, 265, 2, 870, 31, 190, 291, 76, 36, 30, 190, 327, 128, 8, 265, 870, 83, 8, 1362, 76, 1, 1363, 1364, 86, 76, 1, 1365, 354, 2, 871, 5, 34, 14, 168, 1, 292, 4, 649, 77, 1, 220, 41, 1, 872, 53, 3, 327, 12, 40, 52, 1366, 1367, 25, 1368, 873, 328, 355, 9, 410, 2, 410, 9, 355, 1369, 356, 1, 1370, 2, 874, 169, 103, 127, 411, 357, 149, 31, 51, 1371, 329, 107, 12, 358, 412, 875, 1372, 51, 20, 170, 92, 9]\n"
     ]
    }
   ],
   "source": [
    "input_sequence = []\n",
    "output_words = []\n",
    "input_seq_length = 100\n",
    "\n",
    "for i in range(0, n_words - input_seq_length , 1):\n",
    "    in_seq = macbeth_text_words[i:i + input_seq_length]\n",
    "    out_seq = macbeth_text_words[i + input_seq_length]\n",
    "    input_sequence.append([word_2_index[word] for word in in_seq])\n",
    "    output_words.append(word_2_index[out_seq])\n",
    "\n",
    "print(input_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(input_sequence, (len(input_sequence), input_seq_length, 1))\n",
    "X = X / float(vocab_size)\n",
    "\n",
    "y = to_categorical(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (17150, 100, 1)\n",
      "y shape: (17150, 3437)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100, 800)          2566400   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100, 800)          5123200   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 800)               5123200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3437)              2753037   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,565,837\n",
      "Trainable params: 15,565,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(800, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(800, return_sequences=True))\n",
    "model.add(LSTM(800))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 612s 2s/step - loss: 6.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c45519a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first battell worthy macduffe and wee shall take vpon what else remaines to do according to our order sey fare you well do we but finde the tyrants power to night let vs be beaten if we can not fight macd make all our trumpets speak giue the all breath those clamorous harbingers of blood death exeunt alarums continued scena septima enter macbeth macb they haue tied me to stake can not flye but beare like must fight the course what he that was not borne of woman such one am to feare or none enter young seyward sey what\n"
     ]
    }
   ],
   "source": [
    "random_seq_index = np.random.randint(0, len(input_sequence)-1)\n",
    "random_seq = input_sequence[random_seq_index]\n",
    "\n",
    "index_2_word = dict(map(reversed, word_2_index.items()))\n",
    "\n",
    "word_sequence = [index_2_word[value] for value in random_seq]\n",
    "\n",
    "print(' '.join(word_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    int_sample = np.reshape(random_seq, (1, len(random_seq), 1))\n",
    "    int_sample = int_sample / float(vocab_size)\n",
    "\n",
    "    predicted_word_index = model.predict(int_sample, verbose=0)\n",
    "\n",
    "    predicted_word_id = np.argmax(predicted_word_index)\n",
    "    seq_in = [index_2_word[index] for index in random_seq]\n",
    "\n",
    "    word_sequence.append(index_2_word[ predicted_word_id])\n",
    "\n",
    "    random_seq.append(predicted_word_id)\n",
    "    random_seq = random_seq[1:len(random_seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first battell worthy macduffe and wee shall take vpon what else remaines to do according to our order sey fare you well do we but finde the tyrants power to night let vs be beaten if we can not fight macd make all our trumpets speak giue the all breath those clamorous harbingers of blood death exeunt alarums continued scena septima enter macbeth macb they haue tied me to stake can not flye but beare like must fight the course what he that was not borne of woman such one am to feare or none enter young seyward sey what and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and\n"
     ]
    }
   ],
   "source": [
    "final_output = \"\"\n",
    "for word in word_sequence:\n",
    "    final_output = final_output + \" \" + word\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "venv-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
